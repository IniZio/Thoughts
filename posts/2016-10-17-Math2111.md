---
title: Math2111
category: Study
tags: [ math2111 ]
date: 2016-10-17
filename: 2016-10-17-Math2111
---

## L2

- Coeffienient Matrix: put the left side of system of equations in matrix
  $
  \begin{pmatrix}
   1 & 1 & 0 \\
   2 & 2 & 9
  \end{pmatrix} $
- Augumented Matrix: put the whole system of equations in matrix, can solve system of equations
  $
  \begin{pmatrix}
   1 & 1 & 0 | 10\\
   2 & 2 & 9 | 23
  \end{pmatrix} $
- Any matrix is a row echelon form (REF) (i.e. the system of equations is  solved) if satisfy one of:
  - zeros only appear at the buttom
  - each non-zero entry most to right at least one number ahead of upper row
  - All entries in a column below a leading entry must be zeros
- Any matrix is Reduced REF if satisfy REF and one of:
  - leading non-zero entry must be 1
  - 1 is the only non-zero entity

## week202 L3

- pivot position: the postions of leading 1's in the RREF of Matrix
- Systematic way of solving equations:
  - write the system in aug. matrix (M$|$b)
    - (M$|$b) EROs $\rightarrow$ (M'$|$b')
  - spot the pivot pos. and pivot cols.
  - if b' contains a pivot pos, it is not consistent. Otherwise Consistent
    - if consistent, then look at M': if it has free col, then it has infinite solutions, else has unique

## week202 T1

- email: smmcdonnell@ust.hk

- $
    \begin{pmatrix}

  ```
  1 & 3 & -2 & 5 | 4\\
  2 & 8 & -1 & 9 | 9\\
  3 & 5 & -12 & 17 | 7\\
  ```

    \end{pmatrix}
    $ $\longrightarrow$
    $
    \begin{pmatrix}

  ```
  1 & 3 & -2 & 5 | 4\\
  0 & 2 & 3 & -1 | 1\\
  0 & -4 & -6 & 2 | -5\\
  ```

    \end{pmatrix}
    $ $\longrightarrow$
    $
    \begin{pmatrix}{cc | c}

  ```
  1 & 0 & -13/2 & 13/2 | 5/2\\
  0 & 1 & 3/2 & -1/2 | 1/2\\
  0 & 0 & 0 & 0 | -3\\
  ```

    \end{pmatrix}
    $

\section{week202 L4}
\label{sec:week202 L4}

- Linear combination: Let S be a collection of vectors, a linear combination of S is a vector that can be reached by scaled vectors in S  e.g.
    $\begin{pmatrix}

  ```
  2 \\
  4\\
  ```

    \end{pmatrix}$ is a linear combination of $
    \begin{pmatrix}
    1 \\
    2\\
    \end{pmatrix}
    $,
    $\begin{pmatrix}

  ```
  0 \\
  1\\
  0 \\
  ```

    \end{pmatrix}$ is a linear combination of \{$
    \begin{pmatrix}
    1 \\
    0\\
    0\\
    \end{pmatrix},
    \begin{pmatrix}
    1 \\
    1\\
    0\\
    \end{pmatrix}
    $\}

- Linear span of S (Span(S)) is all possible linear combinations of S

- Finding linear combination of vectors = solving system of equations

## L5

- Homogenous equation: a matrix equation/system of linear equations of form Ax = 0. It is always consistent since all x_i s = 0 will solve
- In order to have non-zero (non-trivial) solutions for Homogenous equations, we need to see if there are free columns in A

## T2

- Rank: number of pivots in a matrix
- Mid-term Q: find a condition on $b_i$ such that the system is consistent
- To find number Free variables: RREF the matrix, find the pivot columns, find the free columns, count the free variables
- for an augumented matrix, if each column contains a pivot, then it has no solution (since there will be a row like $0x_1+0x^2+0x^3=1$)

## L6

### Non-homogenous equation

- Ax = b (b != 0)
- Not always consistent
- solutions not of the form span{$x_1$, $x_2$...$x_k$}

#### One way to solve non-homogenous equations:

1. Find a particular solution of it
2. solve the associated homogenous equation Ax=0

##### E.g. $x_1+x_2+x_3+x_4=5$ and $x_3+2x_4=3$

###### Solution:

1. $
   \begin{pmatrix}
   x_1\\
   x_2\\
   x_3\\
   x_4\\
   \end{pmatrix}
   =
   \begin{pmatrix}
   1\\
   2\\
   3\\
   4\\
   \end{pmatrix}
   $
   is a solution of the eq.
2. solve $
   \begin{pmatrix}
   1 & 1 & 1 & 1 | 0 \\
   0 & 0 & 1 & 2 | 0
   \end{pmatrix}
   $\rightarrow$ span{$\begin{pmatrix}1 \\ 1\\0\\0\end{pmatrix},\begin{pmatrix}1 \\ 0\\-2\\1\end{pmatrix}$}
   $
3. all solutions are of the form $\begin{pmatrix}1 \\ 2\\1\\1\end{pmatrix}+\begin{pmatrix}-1 \\ 1\\0\\0\end{pmatrix}+\begin{pmatrix}1 \\ 0\\2\\1\end{pmatrix}$

##### Reason that solution works

1 says that x=$u_0$ is a solution. 2 says that $underline{v}$ is a solution of Ax=0. We claim that x=$u_0$+v is the solution
Proof: LHS = A($u_0$ + v) = A$u_0$ + Av = b + 0 = b = RHS

##### Alternate solution:

solve with matrix normally, use S and T to substitute $x_2$, $x_4$, will get the same thing

### Span

- span as a noun: e.g. A = $\begin{pmatrix}1&1&1\\2&2&2\\3&3&3\end{pmatrix}$, span of A is span{\begin{pmatrix}1\\2\\3\end{pmatrix}}}, which does not span $R^3$
- span as verb: A matrix spans $R^N$ if the matrix can go everywhere in the dimension

### Equavalent throrems of a matrix (one decides whether others are true)

- Ax=b is consistent for each b in $R^m$
- each b in $R^m$ is a linear combination of the columns of A
- The columns of A spans $R^m$
- A has a pivot position on every row

## L7

### Linear dependence

- given S = {$v_1$, $v_2$,....$v_k$}, it is linear dependent if there are redundant directions
- e.g. S = {$\begin{pmatrix} 1\\2\\3 \end{pmatrix}$, $\begin{pmatrix} 1\\2\\3 \end{pmatrix}$,$\begin{pmatrix} 1\\2\\3 \end{pmatrix}$}. It is linear dependent
- a vector is redundant in S if it can be linearly combined by other vectors in S

### Week4 note Exercises:

1. yes
2. yes
3. yes

#### If there is a height $>$ width matrix (e.g. 4*3 matrix), then it is linearly dependent if there are 3 pivot columns

### Matrix transformation

- For the transformation input: x ∈ $R^n$ $\rightarrow$ output Ax ∈ $R^m$, we call this function T: $R^m \rightarrow R^n$
- Function T is a linear transformation if:
  - T(x+y) = T(x) + T(y)
  - T(c*x) = c*T(x)

### Week4 note exercise(2)

1. T(x) = Ax = A$\begin{pmatrix}x_1\\x_2\\x_3 \end{pmatrix}$
2. i.e. which input x gives output 0. So just solve Ax=$\begin{pmatrix}0\\0 \end{pmatrix}$
3. i.e. same as 2 except R.H.S=$\begin{pmatrix}\end{pmatrix}$

## T3

1. i.$\begin{pmatrix} 1 & 0 &1& 1& 2\\ 0 & 2 & 1 & 2& 1 \end{pmatrix}$
   - write $x_1, x_2$ as "f'n" of others
   - $x_1 = -x_3 -x_4 -2x_5$
   - $x_2 = -.5x_3-x_4-.5x_5$
   - $\begin{pmatrix}x_1\\x_2\\x_3\\x_4\\x_5\\ \end{pmatrix} = x_3\begin{pmatrix}-1&-.5&1&0&0\end{pmatrix}$+...
   - basis: a linearly independent spanning set for a vector space ie from the basis you can create some vector space
   - basis for i) is \begin{pmatrix}-1 & -.5 & 1 & 0 & 0 \end{pmatrix},...(too slow :P)
2. i) repeat 1.
3. Check if LI/LD
   - $\{\begin{pmatrix}1\\1\end{pmatrix}\}$ we require c*this = 0 iff c = 0, then its LI. since its != $\begin{pmatrix}0\\0\end{pmatrix}$ matrix, c=0. so Yes
   - $\{\begin{pmatrix}1\\-1\\1\\2\end{pmatrix}, \begin{pmatrix}3\\-2\\1\\3\end{pmatrix}, \begin{pmatrix}5\\-2\\-1\\1\end{pmatrix}\}$: check if LI by row reducing against 0. Have free column, therefore not LI
4. u=x+y, v=x-y, w=2x+3y. Check all pair possibilities check if LI: (recall if LI then all $C_i$s=0)
   - {u,v}: $c_1(x+y)+c_2(x-y)=0$
     $x(c_1+c_2)-y(c_1+c_2)=0$
     if $c_1=c_2$,
     2$c_1$x=0, implies x=0 which contradicts
   - {u,v,w}: assuming its LI, $c_1u+c_2v+u_3w=0$
     plug in all the x's and y 's
     (c_1+c_2+2c_3)x+(c_1+c_2+3c_3)y=0
     should hold because {x,y} are LI
     make a system of coeffiencts with c's to see if =0, solve it
     $\rightarrow$ $\begin{pmatrix}c_1\\c_2\\c_3\end{pmatrix} \rightarrow \begin{pmatrix}-2.5\\.5\\1\end{pmatrix}c_3$.
     implies that {x,y} are LD, which contradicts. Therefore is LD
5. i) for a augumented matix fron LI set,
   - $c_1\begin{pmatrix}1\\0\\0\end{pmatrix} - 0$ iff c_1 = 0

## L8

### injectiveness and surjective

- One-to-one(injective): only one arrow come from each left x element. f(x) = f(y), x=y
- Onto(surjective): only one arrow arrive each right y element.

#### theorem of inverse

- IF $X \rightarrow Y$ is both injective and surjecive, then we have inverse $f^{-1}: Y \rightarrow X$

#### when is T(x)=Ax not trivial?? (T: $R^n \rightarrow R^m$)

- Suppose Ax=0 has a non-trivial solutions x=u != 0
- $\rightarrow$ Then there are more than two solutions where 0=Au,
- $\rightarrow$ T(x)=Ax is not injective

#### When is T(x)=Ax surjective?

- For only b $\exists R^m$, there is an $x_0 \exists R^n$ so that:
- A$x_0$ = b $\Rightarrow (A|b) is consistent for all b$ $\Rightarrow$ columns of A spans R^m

#### week4 P.8 has a table for linear transformations, vectors, matrixes

#### E.g. T: $R^2 \rightarrow R^3$, $T\begin{pmatrix}x\\y\end{pmatrix}=\begin{pmatrix}x\\y\\0\end{pmatrix}$, Is it injective or surjective?

- Standard of T:
- A = $\begin{pmatrix}T\begin{pmatrix}1\\0\end{pmatrix}}T\begin{pmatrix}0\\1\end{pmatrix}\end{pmatrix}$
- Check if T is injective $\Rightarrow$ Check if columns of A is linearly independent
- Since it is L.I., it is injective
- T is surjective $\Rightarrow$ Check if A has pivot on **all rows**.
- Since it doesnot have pivot on last column, it is not surjective

### Injective/Surjective in transforming dimension

- No two arrows eading the ssame target on RHS $\rightarrow$ injective
- LHS dimensoin cannot cover te whole RHS dimension $\rightarrow$ not surjective

## T4

### E.g.1 Identiry the domain/codomain of the matrix transformations given by following:

1. A = [1,2,1\\1,2,2]
2. [1,2,1,1\\1,2,0,1\\0,2,1,2\\1,-2,2,-2]
3. [1,0,2,-2\\3,1,4,-6\\0,2,-4,1\\-1,3,5,2\\0,3,7,1]

### E.g.2 Are the linear transformations in E.g.1 one-to-one or onto?

- Theorem: let A be a standard mtx of a LT T: $R^n\rightarrow R^m$
  1.T is onto $\equiv$ cols of A span $R^m$ $\equiv$ pivot in every row
  1. T is one-to-one $\equiv$ cols of A are LI $\equiv$ pivot in every col

1. check if cols span $R^2$. A has pivots on every colmn but has free variable. So it is onto but not one-to-one
2. onto, not one-to-one
3. one-to-one, not onto

### E.g.4 $T: R^n \rightarrow R^m$. what can you say about m,n?

i.

- T is one-to-one
- if has pivots in ever cols then n $<=$ m
  - i.e. less cols than rows $\equiv$ less variables than equations

j.

- T is onto
- pivots in every row
  - $\Rightarrow$ n $>=m$ $\equiv$ more variables than eqns

### E.g.3 $T: R^n \rightarrow R^m$: T[1\\2] = [3\\1\\-5], T[-1\\1]=[0\\-4\\2]. FInd the standard matrix A of T. Is T one-to-one or onto?

- definition matrix A s.t. Tx = Ax $\all$ X $\exists R^n$ is the standard matrix of T, i.e. A = {$Te_1....,Te^n$}
- A(1,-1\\2,1) =  [3,0\\1,-4\\-5,2]
- A = [3,0\\1,-4\\-5,2][1,-1\\2,1]^-1[1,-1\\2,1]^-1
- A = [1,1\\3,-1\\-3,-1]
- = [1,0\\0,1\\0,0]
- Therefore not onto but is one-to-one

### E.g.10 Let E  [0,0,0\\5,0,0\\0,0,0], A be any 3*4 matrix

1. compute EA, describe it

- $\Rightarrow$ $[0,0,0,0\\5a_{11},5a_{12},5a_{13},5a_{14}\\0,0,0,0]$. We have $5r_1$ adeded to second row, and all other rows are multiplied by zero

### Orthnogonal means(I): I = $A^TA$

### E.g.13 Let A be 2*2, orthnogonal, show $\exists \theta$ s.t.:

- A =  {$\cos{\theta}, \sin{\theta}\\ \sin{\theta}, -\cos{\theta}$}
- A $A^T$ = [1,0\\0,1] so it is

## L9

#### Proving stuff with inverse often involve multiplying the original matrix

#### if ad-bc != 0;

- $\begin{pmatrix} a & b\\c&d \end{pmatrix}$ is invertible with inverse $\frac{1}{ad-bc}\begin{pmatrix} d & -b\\-c&a \end{pmatrix}$

### Getting inverse:

- Suppose A is the 3*3 matrix to be inversed, B is a matrix $\begin{pmatrix}1&0&0\\0&1&0\\0&0&1\end{pmatrix}$
- (A| B). process it as if solveing a system of equations of A.
- If A becomes identity, B in the end is the inverse of A. Otherwise A is not invertible

## L10

##### Elementary matrix:

- identify matrix that went through three types of elementary rowo operation:
  - row switching
  - row multiplication
  - row addition
- ERO can be calculated by multiplying the matrix with a elementary matrix, with elementary matrix before the matrix itself

#### Determinant:

- Usage: For checking whether a matrix is invertible or not
- Definition: 
  - for invertible matrix, determinant is the matrix itself
  - else: e.g. $det\begin{pmatrix}a&b\\c&d\end{pmatrix} = ad-bc$
  - e.g. for 3*3 matrix: a(ei-fh)-d(bi-ch)+g(bf-ce). **Remember** consesecutive -'s
  - det of 4*4 $\to$ 4 dets of 3 *3 $\to$ $4\times3$ dets of 2 *2
- Techniques:
  1. det of upper $\triangle$ matrix: since others will be 0, just recursive top left corner's determinant, so u will get multiplying all numbers on diagonal in the end.

## L11

##### E.g.1  ERO type 3: to make $\begin{pmatrix}1&20\\3&40\end{pmatrix} \to \begin{pmatrix}1&2\\3&4\end{pmatrix}$

- $\det \begin{pmatrix}1&2\\3&4\end{pmatrix} = 1/10 \times \det \begin{pmatrix}1&20\\3&40\end{pmatrix}$
- $\det \begin{pmatrix}1&20\\3&40\end{pmatrix} = 10 \times \det \begin{pmatrix}1&2\\3&4\end{pmatrix}$

##### E.g.2 ERO type 2: $\begin{pmatrix}7&8&10\\4&5&6\\1&2&3\end{pmatrix} = -1 \times \begin{pmatrix}1&2&3\\4&5&6\\7&8&10\end{pmatrix}$

- =$-1\times \begin{pmatrix}7&8&10\\0&-3&-6\\1&2&3\end{pmatrix}$ Type 1
- =$-1\times -3 \times \begin{pmatrix}7&8&10\\0&1&2\\1&2&3\end{pmatrix}$ Type 3
- ... =  =$-1\times \begin{pmatrix}7&8&10\\0&-3&6\\0&0&1\end{pmatrix}$ Type 1
- =3

#### A is invertible $\Leftrightarrow$  $\det(a) != 0$

- Proof: if A is invertible,

  A $\to$ I (after EROS)
  $\det (E_k \times (E_{k-1)...E_1 \times A) = \det {I_n}$

  .. $\Leftrightarrow \det{A}!=0$

   If A is singular,
  A $\to B$ (after EROs), need to prove B = 0

  (hint: B must be upper $\triangle$ matrix)

#### Checking if linearly independent $\Leftrightarrow$ checking if determinant != 0 (only works for square matrix )

#### If A $\to (ERO) $B, E is elementary matrix, then

- B = EA
- det(EA) = det(B) = det(E)det(A)

## T6

#### How do EROs affect determinat:

| Type of det                              | effect on det     |
| ---------------------------------------- | ----------------- |
| Add $cr_n+r_m$                           | no effect         |
| swap $r_n$ with $r_m$                    | change sign       |
| scale a row i.e. multiply by c, c $\exists R$ | multiply det by c |

#### Cofactor expansion:

- Let $A_{ij}$ be the $(n-1)^2$ submatrix obtained by deleting the bla bla... tl:dr breaking break determinant to smaller

1. $\begin{vmatrix} 2&3\\0&4 \end{vmatrix}$
   = ad-bc = 8

2. ​

   1. $\begin{vmatrix}2&1\\1&2\end{vmatrix}$ i.e. A
      =3
   2. $\begin{vmatrix}-2&-1\\-1&-2\end{vmatrix}$ i.e. --A
      = 3
   3. det(2A)
      = $3\times2\times2=12$
   4. $\begin{vmatrix}1&-2\\-1&3\end{vmatrix}$
      = 1

3. Use cofactor expansion to compute the determinant $\begin{vmatrix}9&0&0&2\\7&3&2&8\\3&0&0&0\\5&-3&1&11\end{vmatrix}$

   ==*== Do cofactor expansion on row with more zeros. Here choose 3^rd^ row
   = 3$\begin{vmatrix}0&0&2\\3&2&8\\-3&1&11\end{vmatrix}$
   ... = 18

4. Given $\begin{vmatrix}a&b&c\\d&e&f\\g&h&i\end{vmatrix}=2$

   1. $\begin{vmatrix}g&h&i\\d&e&f\\a&b&c\end{vmatrix}$
      its a row change from A, so = -2
   2. $\begin{vmatrix}a+3g&b+3h&c+3i\\d&e&f\\g&h&i\end{vmatrix}=2$
      = 2 still

5. Determinant of matrix containing ___________

   1. a zero row
      = 0
   2. 2 same rows
      same as (1) = 0
   3. 2 proportional row
      same as (1) = 0

6. A = $\begin{vmatrix}a&b&c\\d&e&f\\g&h&i\end{vmatrix}$, B=$\begin{vmatrix}u&v&w\\d&e&f\\g&h&i\end{vmatrix}$, C=$\begin{vmatrix}a+u&b+v&c+w\\d&e&f\\g&h&i\end{vmatrix}$ . Find relationship between them
   A = $a\begin{vmatrix}e&f\\h&i\end{vmatrix}-b\begin{vmatrix}d&f\\g&i\end{vmatrix}+c\begin{vmatrix}d&e\\g&h\end{vmatrix}$ = a(ei-fh)-b(di-fg)+c(dh-eg)
   B = ... = u(ei-fh)-v(di-fg)+w(dh-eg)
   C = ... = (a+u)(ei-fh)-(b+v)(di-fg)+(c+w)(dh-eg) = A+B
   ==*== Their matrix do not follow the relationship tho

7. FInd $\begin{vmatrix}A\end{vmatrix} $ in terms of X. Find x s.t. A is not invertible

   1. $\begin{vmatrix}1&x&x^2&x^3\\x^3&1&x&x^2\\x^2&x^3&1&x\\x&x^2&x^3&1\end{vmatrix}$ can do row reduce first
      ... = $(1-x^4)^3$ = \begin{vmatrix}A\end{vmatrix} 